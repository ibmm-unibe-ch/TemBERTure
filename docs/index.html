<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TemBERTure: Predicting Protein Thermostability</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 25x;
            padding: 25x;
            background-color: #f4f4f4;
            color: #333;
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }
        .container {
            display: flex;
            flex: 1;
        }
        .sidebar {
            width: 200px;
            background-color: #333; /* Background color darker */
            color: #fff; /* Text color white */
            padding: 20px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            height: 100vh;
            overflow-y: auto;
            border-right: 2px solid #444;
            position: fixed; /* Fixed sidebar */
            top: 0;
            left: 0;
        }
        .sidebar h2 {
            font-size: 1.4em;
            color: #F28C28;
            border-bottom: 2px solid #F28C28;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        .sidebar ul {
            list-style-type: none;
            padding: 0;
        }
        .sidebar ul li {
            margin: 15px 0;
        }
        .sidebar ul li a {
            color: #ddd; /* Link color lighter */
            text-decoration: none;
            font-size: 1.1em;
            display: block;
            padding: 10px;
            border-radius: 4px;
        }
        .sidebar ul li a:hover {
            background-color: #444; /* Darker background on hover */
            text-decoration: underline;
        }
        .sidebar ul li a.active {
            font-weight: bold;
            color: #F28C28; /* Active link color */
            background-color: #555; /* Background color for active link */
        }
        .content {
            margin-left: 0px; /* Adjust margin to match sidebar width */
            margin-right: 0px; /* Adjust margin to match sidebar width */
            padding: 20px;
            background-color: #ffffff;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            overflow-y: auto; /* Allow vertical scrolling */
            flex: 1;
            height: 100vh;
            box-sizing: border-box;
        }
        .center {
            text-align: center;
        }
        h1 {
            font-size: 2.5em; /* Aumenta la dimensione del titolo h1 */
            color: #F28C28;
            margin-bottom: 20px;
        }
        
        h2 {
            font-size: 2em; /* Aumenta la dimensione del titolo h2 */
            color: #F28C28;
            margin-bottom: 15px;
        }
        
        h3 {
            font-size: 1.75em; /* Aumenta la dimensione del titolo h3 */
            color: #F28C28;
            margin-bottom: 10px;
        }

        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
        }
        p, ul, pre {
            line-height: 1.6;
        }
        a {
            color: #0066cc;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .code-block {
            background-color: #f9f9f9;
            border-left: 3px solid #D35400;
            padding: 10px;
            margin: 10px 0;
            overflow-x: auto;
        }
        .caption {
            text-align: center;
            font-size: 0.9em;
            color: #777;
            margin-top: 5px;
        }
        footer {
            text-align: center;
            margin-top: 20px;
            padding: 10px 0;
            border-top: 1px solid #ddd;
            font-size: 0.9em;
            color: #777;
        }
        strong {
            font-weight: bold;
        }
    </style>
</head>
<body>
        <div class="content">
            <div class="center">
                <img title="logo" alt="TemBERTure logo" src="img/logo.png" width="600" height="300">
                <br/><br/>
                <a href="https://academic.oup.com/bioinformaticsadvances/article/4/1/vbae103/7713394">
                    <img src="http://img.shields.io/badge/DOI-10.1093/bioadv/vbae103-F28C28.svg" alt="DOI:10.1093/bioadv/vbae103">
                </a>
            </div>

            <div class="center">
                <h1>Behind the paper: TemBERTure — Unraveling the secrets of protein thermostability with Deep Learning</h1>
            </div>

            <p id="what-if">TemBERTure is a deep learning model that predicts a protein's thermostability class and melting point from its amino acid sequence, providing a more efficient method for understanding and engineering protein stability.</p>

            <h3>What if we could predict protein thermostability just from its sequence?</h3>
            <p>Proteins are the versatile <strong>building blocks of life</strong>, with immense potential for biotechnological applications. However, their utility is often constrained by their <strong>thermal stability</strong>. By understanding the intricacies of protein structure and the factors influencing thermal stability, we can harness this knowledge to design novel proteins with tailored properties. Proteins that withstand <strong>high temperatures</strong> could accelerate chemical reactions, cut production costs, and enhance efficiency. Traditionally, determining a protein's thermostability has been a laborious process. But what if we could predict it simply by looking at its sequence?</p>
            <p>That is exactly what we aimed to do in our recent study. We explored the potential of <strong>deep learning</strong> to predict protein thermostability directly from their amino acid sequences. Think of it like teaching a computer to predict a book's genre based on its first few sentences.</p>

            <h3 id="new-perspective"><strong>A new perspective on proteins: bridging Biology and Linguistics</strong></h3>
            <p>How do we decipher the language of proteins? Just as <strong>words</strong> form sentences, proteins are composed of chains of <strong>amino acids</strong>. In the same way that natural languages adhere to strict <strong>grammatical rules</strong>, proteins follow precise <strong>physicochemical principles</strong>.</p>
            <p>To unravel the complexities of these biological sequences, we harnessed the power of deep learning. We specifically turned to BERT, a state-of-the-art natural language processing model, to analyze protein sequences as if they were linguistic text. This allowed us to uncover hidden patterns that correlate with protein stability. Our efforts culminated in the development of <strong>TemBERTure</strong>, an innovative framework designed to predict protein thermostability with state-of-the-art accuracy.</p>
            <p>TemBERTure consists of three key components:</p>
            <ul>
                <li><strong>TemBERTure<sub>DB</sub></strong>: A meticulously curated database of thermophilic and non-thermophilic protein sequences, serving as the primary training resource.</li>
                <li><strong>TemBERTure<sub>CLS</sub></strong>: A classifier that determines whether a protein is thermophilic (able to withstand high temperatures) or non-thermophilic.</li>
                <li><strong>TemBERTure<sub>Tm</sub></strong>: A regression model that predicts the melting temperature of a protein based on its primary sequence.</li>
            </ul>

            <div class="center">
                <img src="img/F1_b.png" alt="architecture" width="20%">
                <p class="caption">TemBERTure<sub>CLS</sub> model architecture was based on the proBERT-BFD[1] framework, with lightweight bottleneck adapter layers[2][3] (shown in gray)</p>
            </div>

            <h3 id="lifeblood"><strong>The lifeblood of a model is its data</strong></h3>
            <p>The foundation of any robust NLP model lies in the <strong>diversity and quality of its data</strong>, and the journey of TemBERTure exemplifies this principle. Early in our research, we realized that existing datasets were insufficient, lacking the size and diversity for effective model generalization. This led us to create TemBERTureDB, a comprehensive database that would empower our model to predict protein thermostability accurately.</p>
            <p>We began our data-gathering effort with the Meltome Atlas, which provided essential experimental data of protein thermal stability across diverse organisms. However, we needed even more diverse data to ensure the robustness of our model. Thus, we compiled information from additional sources, including ProThermDB, UniProtKB, and BacDive, to create a rich resource encompassing both thermophilic and non-thermophilic sequences.</p>
            <p>Building this high-quality database was no small feat. It required months of meticulous effort and (more than) occasional frustrations, as we navigated the complexities of data integration, handling varying formats, incomplete datasets, and inconsistent annotations. Despite the <strong>challenges</strong>, we knew this was essential to lay a solid foundation for our model's success.</p>
            <p>TemBERTure<sub>DB</sub> is more than just a collection of data; it is the <strong>lifeblood of our model</strong>. By investing in this resource, we ensured that our model could transcend the limitations of existing approaches, paving the way for more accurate and informative predictions of protein thermostability.</p>

            <div class="center">
                <img src="img/F1_A.png" alt="database" width="30%">
                <p class="caption">TemBERTure<sub>DB</sub> creation pipeline</p>
            </div>

            <h3 id="structural-secrets"><strong>Can protein sequences alone reveal their structural secrets?</strong></h3>
            <div class="center">
                <img src="img/3WV9_D.gif" width="1000" alt="Protein structure">
                <p class="caption">Cartoon representation of 3WV9 (chain D) PDB. The width and color indicate the attention score values, with regions with higher attention scores appearing thicker and redder.</p>
            </div>

            <p>Imagine reading a novel, where you are on the lookout for key plot points that reveal the story’s twists and turns. Just as you focus on these pivotal moments to grasp the essence of the narrative, deep learning models like transformers use <strong>attention scores</strong> to zero in on crucial elements within a sequence.</p>
            <p>In TemBERTure, attention scores help the model focus on the sections of a protein sequence <strong>most relevant</strong> to stability. Since these patterns are not immediately visible to the human eye, we decided to investigate how attention scores align with the 3D structures of proteins.</p>
            <p>Could TemBERTure deduce <strong>structural information</strong> solely from the sequence? Specifically, what aspects make a protein stable or unstable? By mapping attention scores onto protein structures, we discovered a fascinating pattern: higher attention scores consistently concentrated in specific areas, such as helical regions and the protein core, across homologous proteins. This finding was like discovering that, regardless of the complexity of a novel, certain plot points always hold more weight in conveying the story.</p>
            <p>These findings demonstrate that TemBERTure naturally prioritizes structurally significant elements when assessing thermostability. The model’s ability to <strong>synthesize both sequence and structural information</strong> leads to more accurate predictions, highlighting its sophisticated approach and opening new avenues for exploring thermostability based on sequence data alone.</p>

            <h3 id="apply-tember">Apply TemBERTure to your protein sequence!</h3>
            <div class="code-block">
                <pre>
                    <code>
seq = 'MEKVYGLIGFPVEHSLSPLMHNDAFARLGIPARYHLFSVEPGQVGAAIAGVRALGIAGVNVTIPHKLAVIPFLDEVDEHARRIGAVNTIINNDGRLIGFNTDGPGYVQALEEEMNITLDGKRILVIGAGGGARGIYFSLLSTAAERIDMANRTVEKAERLVREGEGGRSAYFSLAEAETRLDEYDIIINTTSVGMHPRVEVQPLSLERLRPGVIVSNIIYNPLETKWLKEAKARGARVQNGVGMLVYQGALAFEKWTGQWPDVNRMKQLVIEALRR'

# Initialize TemBERTureCLS model with specified parameters
from temBERTure import TemBERTure
model = TemBERTure(
    adapter_path='./temBERTure/temBERTure_CLS/',  # Path to the model adapter weights
    device='cuda',                                # Device to run the model on
    batch_size=1,                                 # Batch size for inference
    task='classification'                         # Task type (e.g., classification for TemBERTureCLS)
                    </code>
                </pre>
                <pre>
                    <code>
In [1]: model.predict([seq])
100%|██████████████████████████| 1/1 [00:00<00:00, 22.27it/s]
Predicted thermal class: Thermophilic
Thermophilicity prediction score: 0.999098474215349
Out[1]: ['Thermophilic', 0.999098474215349]
                    </code>
                </pre>
            </div>

            <h3 id="improve">How can we improve?</h3>
            <p>While TemBERTure marks a major leap forward, there is still room for growth. Beyond refining classification capabilities, a key area for improvement lies in predicting protein melting temperatures.</p>
            <p><strong>Expanding the database</strong> to include more diverse and comprehensive datasets will boost the model’s accuracy and generalizability. Moreover, integrating <strong>experimental data</strong> on protein stability across various environmental conditions could offer a richer, more nuanced understanding of thermostability.</p>
            <p>As the field evolves, we hope TemBERTure will spark further exploration and unlock new potentials in harnessing the <strong>power of proteins</strong>.</p>
            <p>For those interested in exploring TemBERTure further, the model and its data are available on <a href="https://github.com/ibmm-unibe-ch/TemBERTure">GitHub</a>. TemBERTureDB can be found on <a href="https://doi.org/10.5281/zenodo.10931927">Zenodo</a>, which also hosts the protein sequences.</p>

            <h3 id="references">References</h3>
            <p>
                [1] A. Elnaggar et al., “ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning,” IEEE Trans. Pattern Anal. Mach. Intell., vol. 44, no. 10, pp. 7112–7127, Oct. 2022, doi: 10.1109/TPAMI.2021.3095381.
                <br>
                [2] N. Houlsby et al., “Parameter-Efficient Transfer Learning for NLP.” arXiv, Jun. 13, 2019. Accessed: Feb. 14, 2024. http://arxiv.org/abs/1902.00751
                <br>
                [3] C. Poth et al., “Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning,” 2023, doi: 10.48550/ARXIV.2311.11077.
            </p>
        </div>
    </div>
</body>
</html>
